{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "import gpytorch\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\") #please be really sure about this one "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultitaskGPModel(gpytorch.models.ExactGP): #Multi Class GP with 6 (correlated) outputs\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.MultitaskMean(\n",
    "            gpytorch.means.ConstantMean(), num_tasks=6\n",
    "        )\n",
    "        self.covar_module = gpytorch.kernels.MultitaskKernel(\n",
    "            gpytorch.kernels.RBFKernel(ard_num_dims=5), num_tasks=6, rank=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "\n",
    "## Data reformatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter_data_by_GEN: read full simulation data & filter for sequenced time points\n",
    "def filter_data_by_GEN(data_path, values): \n",
    "    df = pd.read_csv(data_path, sep='\\t', header=0) #read data \n",
    "    df['GEN'] = df['GEN'] - 1 #change from 1-based to 0-based\n",
    "    filtered_df = df[df['GEN'].isin(values)] #filter for empirical available time points \n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "#select_columns_by_names: subset training data based on column names \n",
    "def select_columns_by_names(df, column_names):\n",
    "    selected_columns = df[df['GEN']== 0] #for parameter extraction: removes duplicated entries\n",
    "    selected_columns = selected_columns[column_names]\n",
    "    selected_columns = selected_columns.to_numpy(dtype = \"float\")\n",
    "    return torch.from_numpy(selected_columns).float().contiguous()\n",
    "\n",
    "\n",
    "#get_CN_for_GEN get CN ( = response) for specific generation GEN\n",
    "def get_CN_for_GEN(df, GEN):\n",
    "    filtered_df = df[df['GEN'] == GEN] #filter for specific GEN\n",
    "    \n",
    "    if filtered_df.empty:\n",
    "        return None \n",
    "    else:\n",
    "        CN = filtered_df['m'].to_numpy(dtype = \"float\")\n",
    "        return torch.from_numpy(CN).float().contiguous().flatten()\n",
    "\n",
    "#prep_data: re-formatting of SLiMULATION output for GP \n",
    "def prep_data(data_path, input_params, time_points):\n",
    "    df = filter_data_by_GEN(data_path=data_path, values=time_points) #filter data\n",
    "    df_x = select_columns_by_names(df = df, column_names=input_params) #extract input parameters \n",
    "    y_list = [] \n",
    "\n",
    "    for gen in time_points[1:]: #exclude gen = 0 (no predictions); extract y-values (= CN | GEN)\n",
    "        CN_values = get_CN_for_GEN(df, gen)\n",
    "        y_list.append(CN_values)\n",
    "    y = torch.stack(y_list, dim=-1) #reformat y-values \n",
    "\n",
    "    return df_x, y #return reformatted input & output data \n",
    "\n",
    "#calculate_rmse: calculate RMSE \n",
    "def calculate_rmse(predictions, observations):\n",
    "    squared_error = (predictions - observations)**2\n",
    "    mse = squared_error.mean(dim=0) #MSE across first dimension (= input parameters)\n",
    "    rmse_per_timepoint = torch.sqrt(mse)\n",
    "    overall_rmse = torch.sqrt(squared_error.mean()) #overall RMSE\n",
    "    return rmse_per_timepoint, overall_rmse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#trainGP: train Gaussian process for <iterationcount> iterations, using learning rate <learning_rate> \n",
    "def trainGP(model, likelihood, train_x, train_y, learning_rate, iterationcount):\n",
    "    model.train() #set to training modus\n",
    "    likelihood.train()\n",
    "\n",
    "    # Use the adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr= learning_rate)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    for i in range(iterationcount): #train for <iterationcount> interations \n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_x)\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "        #if (i + 1) % 500==0 or i == 0: #output for tracking of loss on training data \n",
    "            #print('Iter %d/%d - Loss: %.3f' % (i + 1, iterationcount, loss.item()))\n",
    "        if i == (iterationcount-1):\n",
    "            lossCount = loss.item() #save Loss at end of training\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval() #set back to evaluation mode \n",
    "    likelihood.eval()\n",
    "    return model, likelihood, lossCount #return trained model & loss at the end of trianing\n",
    "\n",
    "#GPpredict: predict y|x with GP\n",
    "def GPpredict(df, model, likelihood):\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        predictions = likelihood(model(df))\n",
    "        mean = predictions.mean\n",
    "        lower, upper = predictions.confidence_region() \n",
    "    return lower, mean, upper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN = \"../data/established/20240722/train-LHS-1000-allGen-betaDist-varReg-varP-rescaled.txt\" #path training data\n",
    "PATH_VAL = \"../data/established/20240722/val-LHS-5000-allGen-betaDist-varReg-varP-rescaled.txt\" #path validation data \n",
    "PATH_TEST = \"../data/established/20240722/test-LHS-5000-allGen-betaDist-varReg-varP-rescaled.txt\" #path test data \n",
    "\n",
    "ESTABLISHED_TP = [0, 10, 15, 20, 25, 30, 60] #sequenced time points: established P-element invasion\n",
    "EARLY_TP = [0, 10, 20, 30, 40, 50, 60] #sequenced time points: early P-element invasion\n",
    "INVASION_TYPE = \"established\" #type of invasion (early, established)\n",
    "INPUT_PARAM = ['trans_prob', 'sel_alpha', 'sel_beta', 'l_pi', 'p_te']\n",
    "\n",
    "if INVASION_TYPE not in [\"early\", \"established\"]: #time points used for GP \n",
    "   raise ValueError(\"Specify the type of invasion \\\"early\\\", \\\"established\\\"\")\n",
    "else:\n",
    "   if INVASION_TYPE == \"early\":\n",
    "        TIME_POINTS = EARLY_TP\n",
    "   else: \n",
    "        TIME_POINTS = ESTABLISHED_TP\n",
    "\n",
    "LEARNING_RATE = 0.01 #GP: learning rate \n",
    "ITERATION_COUNT = 50 #GP: number of iterations per training round \n",
    "TRAINING_ROUNDS = 40 #GP: number of training rounds\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GP\n",
    "\n",
    "## Set up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 5])\n",
      "torch.float32\n",
      "torch.Size([1000, 6])\n",
      "torch.float32\n",
      "torch.Size([5000, 5])\n",
      "torch.float32\n",
      "torch.Size([5000, 6])\n",
      "torch.float32\n",
      "torch.Size([5000, 5])\n",
      "torch.float32\n",
      "torch.Size([5000, 6])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = prep_data(data_path=PATH_TRAIN, input_params=INPUT_PARAM, time_points=TIME_POINTS) #generate training data \n",
    "val_x, val_y = prep_data(data_path=PATH_VAL, input_params=INPUT_PARAM, time_points=TIME_POINTS) #generate validation data \n",
    "test_x, test_y = prep_data(data_path=PATH_TEST, input_params=INPUT_PARAM, time_points=TIME_POINTS) #generate test data \n",
    "\n",
    "for i in train_x, train_y, val_x, val_y, test_x, test_y : #sanity checks \n",
    "    print(i.shape)\n",
    "    print(i.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=6) #set-up GP \n",
    "model = MultitaskGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Round 1 out of 40. Please be patient...\n",
      "Training Round 2 out of 40. Please be patient...\n",
      "Training Round 3 out of 40. Please be patient...\n",
      "Training Round 4 out of 40. Please be patient...\n",
      "Training Round 5 out of 40. Please be patient...\n",
      "Training Round 6 out of 40. Please be patient...\n",
      "Training Round 7 out of 40. Please be patient...\n",
      "Training Round 8 out of 40. Please be patient...\n",
      "Training Round 9 out of 40. Please be patient...\n",
      "Training Round 10 out of 40. Please be patient...\n",
      "Training Round 11 out of 40. Please be patient...\n",
      "Training Round 12 out of 40. Please be patient...\n",
      "Training Round 13 out of 40. Please be patient...\n",
      "Training Round 14 out of 40. Please be patient...\n",
      "Training Round 15 out of 40. Please be patient...\n",
      "Training Round 16 out of 40. Please be patient...\n",
      "Training Round 17 out of 40. Please be patient...\n",
      "Training Round 18 out of 40. Please be patient...\n",
      "Training Round 19 out of 40. Please be patient...\n",
      "Training Round 20 out of 40. Please be patient...\n",
      "Training Round 21 out of 40. Please be patient...\n",
      "Training Round 22 out of 40. Please be patient...\n",
      "Training Round 23 out of 40. Please be patient...\n",
      "Training Round 24 out of 40. Please be patient...\n",
      "Training Round 25 out of 40. Please be patient...\n",
      "Training Round 26 out of 40. Please be patient...\n",
      "Training Round 27 out of 40. Please be patient...\n",
      "Training Round 28 out of 40. Please be patient...\n",
      "Training Round 29 out of 40. Please be patient...\n",
      "Training Round 30 out of 40. Please be patient...\n",
      "Training Round 31 out of 40. Please be patient...\n",
      "Training Round 32 out of 40. Please be patient...\n",
      "Training Round 33 out of 40. Please be patient...\n",
      "Training Round 34 out of 40. Please be patient...\n",
      "Training Round 35 out of 40. Please be patient...\n",
      "Training Round 36 out of 40. Please be patient...\n",
      "Training Round 37 out of 40. Please be patient...\n",
      "Training Round 38 out of 40. Please be patient...\n",
      "Training Round 39 out of 40. Please be patient...\n",
      "Training Round 40 out of 40. Please be patient...\n"
     ]
    }
   ],
   "source": [
    "for i in range(TRAINING_ROUNDS):\n",
    "        print(f\"Training Round {i+1} out of {TRAINING_ROUNDS}. Please be patient...\")\n",
    "        if i == 0 : #if new training attempt, create new file with header\n",
    "                with open('../models/stats-GP.txt', 'w') as file:\n",
    "                    myheader = \"invasion_type\\tround\\ttraining_loss\\ttraining_rmse\\tvalidation_rmse\\tneg_count_val\\n\"\n",
    "                    file.write(myheader)\n",
    "                    file.close()\n",
    "        with open('../models/stats-GP.txt', 'a') as file:\n",
    "            model, likelihood, loss = trainGP(model=model, likelihood=likelihood,train_x=train_x, train_y=train_y, iterationcount=ITERATION_COUNT, learning_rate=LEARNING_RATE) #train\n",
    "            torch.save(model.state_dict(), f\"../models/P-GP-{i}.pth\") #save model snapshot \n",
    "            _, pred_train, _ = GPpredict(df = train_x, model=model, likelihood=likelihood) #predicted output | training data \n",
    "            _, rmse_train = calculate_rmse(predictions=pred_train, observations=train_y) #RMSE training data \n",
    "            _, pred_val,_ = GPpredict(df=val_x, model=model, likelihood=likelihood) #predicted output | validation data \n",
    "            _, rmse_val = calculate_rmse(predictions=pred_val, observations=val_y) #RMSE validation data \n",
    "            neg_count = pred_val < 0\n",
    "            neg_count = neg_count.sum().item() #number of negative pred. values \n",
    "\n",
    "            myoutput=f\"{INVASION_TYPE}\\t{i}\\t{loss}\\t{rmse_train}\\t{rmse_val}\\t{neg_count}\\n\" #generate output \n",
    "            file.write(myoutput + '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/P-GP-19.pth\n",
      "tensor(0.6588)\n",
      "0.658774733543396\n",
      "tensor([0.3142, 0.4457, 0.5365, 0.6130, 0.6923, 1.0114])\n",
      "tensor(0.6407)\n"
     ]
    }
   ],
   "source": [
    "stats = pd.read_csv('../models/stats-GP.txt', sep='\\t', header=0) #load model with lowest RMSE on validation data \n",
    "min_id= stats['validation_rmse'].idxmin()\n",
    "toload = f\"../models/P-GP-{stats['round'][min_id]}.pth\"\n",
    "print(toload)\n",
    "model.load_state_dict(torch.load(toload))\n",
    "\n",
    "lower_val, pred_val, upper_val = GPpredict(df=val_x, model=model, likelihood=likelihood) #sanity check \n",
    "_, rmse_val = calculate_rmse(predictions=pred_val, observations=val_y)\n",
    "print(rmse_val)\n",
    "print(stats['validation_rmse'][min_id])\n",
    "\n",
    "lower_test, pred_test, upper_test = GPpredict(df = test_x, model=model, likelihood=likelihood) #predicted output | test data \n",
    "rmse_test_TP, rmse_test = calculate_rmse(predictions=pred_test, observations=test_y) #RMSE test data \n",
    "print(rmse_test_TP)\n",
    "print(rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = filter_data_by_GEN(data_path=PATH_TEST, values=TIME_POINTS)\n",
    "test_df['pred'] = float('nan')\n",
    "test_df['lower'] = float('nan')\n",
    "test_df['upper'] = float('nan')\n",
    "\n",
    "for gen in range(1, len(TIME_POINTS)): #add predicted values & credible interval (attention: no prediction for generation 0)\n",
    "    test_df.loc[test_df['GEN'] == TIME_POINTS[gen], 'pred'] = pred_test[:, (gen-1)].numpy()\n",
    "    test_df.loc[test_df['GEN'] == TIME_POINTS[gen], 'lower'] = lower_test[:, (gen-1)].numpy()\n",
    "    test_df.loc[test_df['GEN'] == TIME_POINTS[gen], 'upper'] = upper_test[:, (gen-1)].numpy()\n",
    "\n",
    "test_df.to_csv('P-GP-predict.txt', sep='\\t', index=False) #save predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPDummy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
