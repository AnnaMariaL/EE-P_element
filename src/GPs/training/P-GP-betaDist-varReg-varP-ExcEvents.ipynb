{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages\n",
    "\n",
    "This section contains the packages necessary for this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import gpytorch\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "from torch.cuda import is_available as cuda_available, empty_cache\n",
    "warnings.filterwarnings(\"ignore\") #please be really sure about this one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip freeze > requirements-01.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes\n",
    "\n",
    "This section contains the - very short - class implementation for the GP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultitaskGPModel(gpytorch.models.ExactGP): #Multi Class GP with 6 (correlated) outputs\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.MultitaskMean(\n",
    "            gpytorch.means.ConstantMean(), num_tasks=6\n",
    "        )\n",
    "        \n",
    "        self.covar_module = gpytorch.kernels.MultitaskKernel( #7 input variables, 6 outputs, simple 1-rank correlation for outputs\n",
    "            gpytorch.kernels.RBFKernel(ard_num_dims=7), num_tasks=6, rank=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "\n",
    "This section contains function used in the GP training.\n",
    "\n",
    "## Functions for: Data reformatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter_data_by_GEN: read full simulation data & filter for sequenced time points\n",
    "def filter_data_by_GEN(data_path, values): \n",
    "    df = pd.read_csv(data_path, sep='\\t', header=0) #read data \n",
    "    df['GEN'] = df['GEN'] - 1 #change from 1-based to 0-based\n",
    "    filtered_df = df[df['GEN'].isin(values)] #filter for empirical available time points \n",
    "    return filtered_df\n",
    "\n",
    "#select_columns_by_names: subset training data based on column names \n",
    "def select_columns_by_names(df, column_names):\n",
    "    selected_columns = df[df['GEN']== 0] #for parameter extraction: removes duplicated entries\n",
    "    selected_columns = selected_columns[column_names]\n",
    "    selected_columns = selected_columns.to_numpy(dtype = \"float\")\n",
    "    return torch.from_numpy(selected_columns).float().contiguous()\n",
    "\n",
    "\n",
    "#get_CN_for_GEN get CN ( = response) for specific generation GEN\n",
    "def get_CN_for_GEN(df, GEN):\n",
    "    filtered_df = df[df['GEN'] == GEN] #filter for specific GEN\n",
    "    if filtered_df.empty:\n",
    "        return None \n",
    "    else:\n",
    "        CN = filtered_df['m'].to_numpy(dtype = \"float\") #m contains avg. P-ele CN/haplotype across n simulations\n",
    "        return torch.from_numpy(CN).float().contiguous().flatten()\n",
    "\n",
    "#prep_data: re-formatting of SLiMULATION output for GP \n",
    "def prep_data(data_path, input_params, time_points):\n",
    "    df = filter_data_by_GEN(data_path=data_path, values=time_points) #filter data\n",
    "    df_x = select_columns_by_names(df = df, column_names=input_params) #extract input parameters \n",
    "    y_list = [] \n",
    "\n",
    "    for gen in time_points[1:]: #exclude gen = 0 (no predictions); extract y-values (= CN | GEN)\n",
    "        CN_values = get_CN_for_GEN(df, gen)\n",
    "        y_list.append(CN_values)\n",
    "    y = torch.stack(y_list, dim=-1) #reformat y-values \n",
    "    if cuda_available():\n",
    "        df_x, y = df_x.cuda(), y.cuda()\n",
    "    return df_x, y #return reformatted input & output data \n",
    "\n",
    "#calculate_rmse: calculate RMSE \n",
    "def calculate_rmse(predictions, observations):\n",
    "    squared_error = (predictions - observations)**2\n",
    "    mse = squared_error.mean(dim=0) #MSE across first dimension (= input parameters)\n",
    "    rmse_per_timepoint = torch.sqrt(mse)\n",
    "    overall_rmse = torch.sqrt(squared_error.mean()) #overall RMSE\n",
    "    return rmse_per_timepoint, overall_rmse\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for: GP handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainGP: train Gaussian process for <iterationcount> iterations, using learning rate <learning_rate> \n",
    "def trainGP(model, likelihood, train_x, train_y, learning_rate, iterationcount):\n",
    "    model.train() #set to training modus\n",
    "    likelihood.train()\n",
    "\n",
    "    # Use the adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr= learning_rate)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    for i in tqdm(range(iterationcount), desc=\"Iterations comple on this training round.\", leave=False): #train for <iterationcount> interations \n",
    "        if cuda_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_x)\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "        #if (i + 1) % 500==0 or i == 0: #output for tracking of loss on training data \n",
    "            #print('Iter %d/%d - Loss: %.3f' % (i + 1, iterationcount, loss.item()))\n",
    "        if i == (iterationcount-1):\n",
    "            lossCount = loss.item() #save Loss at end of training\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval() #set back to evaluation mode \n",
    "    likelihood.eval()\n",
    "    return model, likelihood, lossCount #return trained model & loss at the end of trianing\n",
    "\n",
    "#GPpredict: predict y|x with GP\n",
    "def GPpredict(df, model, likelihood):\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "       predictions = likelihood(model(df))\n",
    "       mean = predictions.mean\n",
    "       lower, upper = predictions.confidence_region() \n",
    "    return lower, mean, upper\n",
    "    # loader = DataLoader(TensorDataset(df), batch_size=128, shuffle=False)\n",
    "    # mean, lower, upper = torch.tensor([0.]), torch.tensor([0.]), torch.tensor([0.])\n",
    "    # with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    #     batchnum = 1\n",
    "    #     for batch in loader:\n",
    "    #         if cuda_available():\n",
    "    #             torch.cuda.empty_cache()\n",
    "    #         print(batchnum)\n",
    "    #         batchnum +=1\n",
    "    #         predictions = likelihood(model(batch[0]))\n",
    "    #         cur_mean = predictions.mean\n",
    "    #         if cuda_available():\n",
    "    #             mean = torch.cat([mean, cur_mean.cpu()])\n",
    "    #             cur_lower, cur_upper = predictions.confidence_region()\n",
    "    #             lower = torch.cat([lower, cur_lower.cpu()])\n",
    "    #             upper = torch.cat([upper, cur_upper.cpu()])\n",
    "    #         else:\n",
    "    #             mean = torch.cat([mean, cur_mean])\n",
    "    #             cur_lower, cur_upper = predictions.confidence_region()\n",
    "    #             lower = torch.cat([lower, cur_lower])\n",
    "    #             upper = torch.cat([upper, cur_upper])\n",
    "    # return lower[1:], mean[1:], upper[1:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables\n",
    "\n",
    "This section contains global variables. If you use the provided file structure, <i>INVASION_TYPE</i> is the only variable that needs to be changed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INVASION_TYPE = \"established\" #type of invasion (early, established)\n",
    "TRAIN_SET_NUM_POINTS = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ESTABLISHED_TP = [0, 10, 15, 20, 25, 30, 60] #sequenced time points: established P-element invasion (do not change)\n",
    "EARLY_TP = [0, 10, 20, 30, 40, 50, 60] #sequenced time points: early P-element invasion (do not change)\n",
    "\n",
    "if INVASION_TYPE not in [\"early\", \"established\"]: #time points used for GP \n",
    "   raise ValueError(\"Specify the type of invasion \\\"early\\\", \\\"established\\\"\")\n",
    "else:\n",
    "   if INVASION_TYPE == \"early\":\n",
    "        TIME_POINTS = EARLY_TP\n",
    "   else: \n",
    "        TIME_POINTS = ESTABLISHED_TP\n",
    "        \n",
    "PATH_TRAIN = f\"../data/{INVASION_TYPE}/train-LHS-{TRAIN_SET_NUM_POINTS}-allGen-betaDist-varReg-varP-ExcEvents-rescaled.txt\" #path training data\n",
    "PATH_VAL = f\"../data/{INVASION_TYPE}/val-LHS-10000-allGen-betaDist-varReg-varP-ExcEvents-rescaled.txt\" #path validation data \n",
    "PATH_TEST = f\"../data/{INVASION_TYPE}/test-LHS-10000-allGen-betaDist-varReg-varP-ExcEvents-rescaled.txt\" #path test data \n",
    "\n",
    "INPUT_PARAM = ['trans_prob', 'sel_alpha', 'sel_beta', 'l_pi', 'p_te', 'p_exc', 'h'] #model parameters\n",
    "\n",
    "\n",
    "LEARNING_RATE = 0.01 #GP: learning rate \n",
    "ITERATION_COUNT = 100 #GP: number of iterations per training round \n",
    "TRAINING_ROUNDS = 50 #GP: number of training rounds: total amount of training = ITERATION_COUNT X TRAINING_ROUNDS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GP\n",
    "\n",
    "## Set up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = prep_data(data_path=PATH_TRAIN, input_params=INPUT_PARAM, time_points=TIME_POINTS) #prep training data \n",
    "val_x, val_y = prep_data(data_path=PATH_VAL, input_params=INPUT_PARAM, time_points=TIME_POINTS) #prep validation data \n",
    "test_x, test_y = prep_data(data_path=PATH_TEST, input_params=INPUT_PARAM, time_points=TIME_POINTS) #prep test data \n",
    "\n",
    "for i in train_x, train_y, val_x, val_y, test_x, test_y : #sanity checks: format... X = 10,000 rows x 7 model parameters; Y = 10,000 rows x 6 P-element copy numbers (time series)\n",
    "    print(i.shape)\n",
    "    print(i.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=6) #set-up GP \n",
    "model = MultitaskGPModel(train_x, train_y, likelihood)\n",
    "if cuda_available():\n",
    "    print(\"Using GPU acceleration\")\n",
    "    likelihood, model = likelihood.cuda(), model.cuda()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training \n",
    "\n",
    "This section contains the actual training of the GP. After Training, there should be <i>TRAINING_ROUNDS</i> model snapshots in the <i>models/INVASIONTYPE</i> directory plus a <i>stats-GP.txt</i> file that contains (among other things) the RMSEs for all model snapshots for the training and validation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(TRAINING_ROUNDS), desc=\"Total training rounds\"):\n",
    "        if i == 0 : #if new training attempt, create new file with header\n",
    "                with open(f\"../models/{INVASION_TYPE}/stats-GP.txt\", 'w') as file:\n",
    "                    myheader = \"invasion_type\\tround\\ttraining_loss\\ttraining_rmse\\tvalidation_rmse\\tneg_count_val\\n\"\n",
    "                    file.write(myheader)\n",
    "                    file.close()\n",
    "        with open(f\"../models/{INVASION_TYPE}/stats-GP.txt\", 'a') as file:\n",
    "            model, likelihood, loss = trainGP(model=model, likelihood=likelihood,train_x=train_x, train_y=train_y, iterationcount=ITERATION_COUNT, learning_rate=LEARNING_RATE) #train\n",
    "            if cuda_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            model_snapshot = model\n",
    "            if cuda_available():\n",
    "                model = model.cpu()  # Save a cpu model even if using GPU acceleration.\n",
    "                torch.save(model.state_dict(), f\"../models/{INVASION_TYPE}/P-GP-{i}.pth\") #save model snapshot \n",
    "                model = model.cuda()\n",
    "            else:\n",
    "                torch.save(model.state_dict(), f\"../models/{INVASION_TYPE}/P-GP-{i}.pth\") #save model snapshot \n",
    "            _, pred_train, _ = GPpredict(df = train_x, model=model, likelihood=likelihood) #predicted output | training data \n",
    "            _, rmse_train = calculate_rmse(predictions=pred_train, observations=train_y) #RMSE training data \n",
    "            _, pred_val,_ = GPpredict(df=val_x, model=model, likelihood=likelihood) #predicted output | validation data \n",
    "            _, rmse_val = calculate_rmse(predictions=pred_val, observations=val_y) #RMSE validation data \n",
    "            neg_count = pred_val < 0\n",
    "            neg_count = neg_count.sum().item() #number of negative pred. values \n",
    "\n",
    "            myoutput=f\"{INVASION_TYPE}\\t{i}\\t{loss}\\t{rmse_train}\\t{rmse_val}\\t{neg_count}\\n\" #generate output \n",
    "            file.write(myoutput + '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "Predict P element invasion dynamics using the GP on the test data and store the results. After running this section, there should be a <i>P-GP-predict.txt</i> file in the <i>pred/INVASION_TYPE</i> directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.read_csv(f\"../models/{INVASION_TYPE}/stats-GP.txt\", sep='\\t', header=0) #load model with lowest RMSE on validation data \n",
    "min_id= stats['validation_rmse'].idxmin()\n",
    "toload = f\"../models/{INVASION_TYPE}/P-GP-{stats['round'][min_id]}.pth\"\n",
    "print(toload)\n",
    "model.load_state_dict(torch.load(toload))\n",
    "\n",
    "lower_val, pred_val, upper_val = GPpredict(df=val_x, model=model, likelihood=likelihood) #sanity check \n",
    "_, rmse_val = calculate_rmse(predictions=pred_val, observations=val_y)\n",
    "print(rmse_val)\n",
    "print(stats['validation_rmse'][min_id])\n",
    "\n",
    "lower_test, pred_test, upper_test = GPpredict(df = test_x, model=model, likelihood=likelihood) #predicted output | test data \n",
    "rmse_test_TP, rmse_test = calculate_rmse(predictions=pred_test, observations=test_y) #RMSE test data \n",
    "print(rmse_test_TP)\n",
    "print(rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = filter_data_by_GEN(data_path=PATH_TEST, values=TIME_POINTS)\n",
    "test_df['pred'] = float('nan')\n",
    "test_df['lower'] = float('nan')\n",
    "test_df['upper'] = float('nan')\n",
    "\n",
    "if cuda_available():\n",
    "    lower_test, pred_test, upper_test = lower_test.cpu(), pred_test.cpu(), upper_test.cpu()\n",
    "\n",
    "for gen in range(1, len(TIME_POINTS)): #add predicted values & credible interval (attention: no prediction for generation 0)\n",
    "    test_df.loc[test_df['GEN'] == TIME_POINTS[gen], 'pred'] = pred_test[:, (gen-1)].numpy()\n",
    "    test_df.loc[test_df['GEN'] == TIME_POINTS[gen], 'lower'] = lower_test[:, (gen-1)].numpy()\n",
    "    test_df.loc[test_df['GEN'] == TIME_POINTS[gen], 'upper'] = upper_test[:, (gen-1)].numpy()\n",
    "\n",
    "test_df.to_csv(f\"../pred/{INVASION_TYPE}/P-GP-predict.txt\", sep='\\t', index=False) #save predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_default",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
