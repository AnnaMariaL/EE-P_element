{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch\n",
    "import gc\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader #batch loading \n",
    "from torch.cuda import is_available as cuda_available, empty_cache #GPU usage \n",
    "\n",
    "from emukit.core import ParameterSpace, ContinuousParameter\n",
    "from emukit.core.initial_designs.latin_design import LatinDesign\n",
    "\n",
    "import warnings \n",
    "#warnings.filterwarnings(\"ignore\") #please be really sure about this one \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultitaskGPModel(gpytorch.models.ExactGP): #Multi Class GP with 6 (correlated) outputs\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.MultitaskMean(\n",
    "            gpytorch.means.ConstantMean(), num_tasks=6\n",
    "        )\n",
    "        self.covar_module = gpytorch.kernels.MultitaskKernel(\n",
    "            gpytorch.kernels.RBFKernel(ard_num_dims=5), num_tasks=6, rank=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "\n",
    "## Data reformatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter_data_by_GEN: read full simulation data & filter for sequenced time points\n",
    "def filter_data_by_GEN(data_path, values): \n",
    "    df = pd.read_csv(data_path, sep='\\t', header=0) #read data \n",
    "    df['GEN'] = df['GEN'] - 1 #change from 1-based to 0-based\n",
    "    filtered_df = df[df['GEN'].isin(values)] #filter for empirical available time points \n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "#select_columns_by_names: subset training data based on column names \n",
    "def select_columns_by_names(df, column_names):\n",
    "    selected_columns = df[df['GEN']== 0] #for parameter extraction: removes duplicated entries\n",
    "    selected_columns = selected_columns[column_names]\n",
    "    selected_columns = selected_columns.to_numpy(dtype = \"float\")\n",
    "    return torch.from_numpy(selected_columns).float().contiguous()\n",
    "\n",
    "\n",
    "#get_CN_for_GEN get CN ( = response) for specific generation GEN\n",
    "def get_CN_for_GEN(df, GEN):\n",
    "    filtered_df = df[df['GEN'] == GEN] #filter for specific GEN\n",
    "    \n",
    "    if filtered_df.empty:\n",
    "        return None \n",
    "    else:\n",
    "        CN = filtered_df['m'].to_numpy(dtype = \"float\")\n",
    "        return torch.from_numpy(CN).float().contiguous().flatten()\n",
    "\n",
    "#prep_data: re-formatting of SLiMULATION output for GP \n",
    "def prep_data(data_path, input_params, time_points):\n",
    "    df = filter_data_by_GEN(data_path=data_path, values=time_points) #filter data\n",
    "    df_x = select_columns_by_names(df = df, column_names=input_params) #extract input parameters \n",
    "    y_list = [] \n",
    "\n",
    "    for gen in time_points[1:]: #exclude gen = 0 (no predictions); extract y-values (= CN | GEN)\n",
    "        CN_values = get_CN_for_GEN(df, gen)\n",
    "        y_list.append(CN_values)\n",
    "    y = torch.stack(y_list, dim=-1) #reformat y-values \n",
    "\n",
    "    return df_x, y #return reformatted input & output data \n",
    "\n",
    "#calculate_rmse: calculate RMSE \n",
    "def calculate_rmse(predictions, observations):\n",
    "    squared_error = (predictions - observations)**2\n",
    "    mse = squared_error.mean(dim=0) #MSE across first dimension (= input parameters)\n",
    "    rmse_per_timepoint = torch.sqrt(mse)\n",
    "    overall_rmse = torch.sqrt(squared_error.mean()) #overall RMSE\n",
    "    return rmse_per_timepoint, overall_rmse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPpredict_batch: prediction with GP with batch loading onto GPU\n",
    "def GPpredict_batch(df, model, likelihood):\n",
    "    if cuda_available(): # Shift data to GPU if available \n",
    "        df = df.cuda()\n",
    "    \n",
    "    loader = DataLoader(TensorDataset(df), batch_size=1024, shuffle=False) # Batch loading onto GPU \n",
    "    lower, mean, upper = [], [], []\n",
    "\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        for batch in loader:\n",
    "            batch_predictions = likelihood(model(batch[0]))\n",
    "            batch_means = batch_predictions.mean\n",
    "            batch_lowers, batch_uppers = batch_predictions.confidence_region()\n",
    "            \n",
    "            if cuda_available():\n",
    "                lower.append(batch_lowers.cpu())\n",
    "                mean.append(batch_means.cpu())\n",
    "                upper.append(batch_uppers.cpu())\n",
    "            else:\n",
    "                lower.append(batch_lowers)\n",
    "                mean.append(batch_means)\n",
    "                upper.append(batch_uppers)\n",
    "\n",
    "    lower = torch.cat(lower, dim=0)\n",
    "    mean = torch.cat(mean, dim=0)\n",
    "    upper = torch.cat(upper, dim=0)\n",
    "    \n",
    "    return lower, mean, upper\n",
    "\n",
    "#trainGP: train Gaussian process for <iterationcount> iterations, using learning rate <learning_rate> \n",
    "def trainGP(model, likelihood, train_x, train_y, learning_rate, iterationcount):\n",
    "    model.train() #set to training modus\n",
    "    likelihood.train()\n",
    "\n",
    "    # Use the adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr= learning_rate)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    for i in range(iterationcount): #train for <iterationcount> interations \n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_x)\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "        #if (i + 1) % 500==0 or i == 0: #output for tracking of loss on training data \n",
    "            #print('Iter %d/%d - Loss: %.3f' % (i + 1, iterationcount, loss.item()))\n",
    "        if i == (iterationcount-1):\n",
    "            lossCount = loss.item() #save Loss at end of training\n",
    "        optimizer.step()\n",
    "        if cuda_available():\n",
    "            empty_cache()\n",
    "\n",
    "    model.eval() #set back to evaluation mode \n",
    "    likelihood.eval()\n",
    "    return model, likelihood, lossCount #return trained model & loss at the end of trianing\n",
    "\n",
    "#singlePrediction: generate prediction for a single input parameter combination\n",
    "    #trans_prob: transposition probability\n",
    "    #sel_alpha: alpha parameter, DFE beta distribution\n",
    "    #sel_beta: beta parameter, DFE beta distribution\n",
    "    #l_pi: proportion of chromosome with regulatory function\n",
    "    #model: GP model\n",
    "    #likelihood: GP likelihood \n",
    "def singlePrediction(trans_prob, sel_alpha, sel_beta, l_pi, p_te, model, likelihood):\n",
    "    param_array = np.array([trans_prob, sel_alpha, sel_beta, l_pi, p_te]) #generate input param array\n",
    "    param_array = torch.from_numpy(param_array).float().contiguous() #reformat \n",
    "    param_array = param_array.view(1, -1)\n",
    "    _, pred_mean, _ = GPpredict_batch(df=param_array, model=model, likelihood=likelihood) #obtain GP prediction\n",
    "    return pred_mean\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical Data Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate_sum_nrsme: calculate NRMSE sum between empirical data and GP prediction\n",
    "def calculate_sum_nrmse(obs_df, pred_torch, time_points):\n",
    "    pred = pred_torch.numpy()\n",
    "    diff_stat = []\n",
    "\n",
    "    for gen in range(len(time_points)):\n",
    "        CN_gen = obs_df[obs_df['gen'] == time_points[gen]]['CN'].to_numpy()\n",
    "        nrmse_gen = np.sqrt(np.sum((CN_gen - pred[gen])**2)/len(CN_gen))/np.mean(CN_gen)\n",
    "        diff_stat.append(nrmse_gen)\n",
    "    return np.sum(diff_stat)\n",
    "\n",
    "\n",
    "#top_x_candidates: return top_x rows of numpy array x with lowest score \n",
    "def top_x_candidates(x, score, top_x):\n",
    "    y = np.column_stack((x, score))\n",
    "    y_sorted = y[y[:, -1].argsort()]\n",
    "    return y_sorted[:top_x]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN_EST = \"../data/established/20240722/train-LHS-1000-allGen-betaDist-varReg-varP-rescaled.txt\" #path training data, established\n",
    "PATH_VAL_EST = \"../data/established/20240722/val-LHS-5000-allGen-betaDist-varReg-varP-rescaled.txt\" #path validation data, established \n",
    "PATH_STATS_EST = \"../models/established-betaDist-varReg-varP-domainChange/\" #path to model snapshots & RMSE file, established\n",
    "PATH_EMP_EST = \"../data/established/P-established-emp.txt\" #empirical data (generation \\t replicate \\t CN), established \n",
    "ESTABLISHED_TP = [0, 10, 15, 20, 25, 30, 60] #sequenced time points: established P-element invasion\n",
    "\n",
    "PATH_TRAIN_EARLY = \"../data/early/20240720/train-LHS-1000-allGen-betaDist-varReg-varP-scaled.txt\" #path training data, established\n",
    "PATH_VAL_EARLY = \"../data/early/20240720/val-LHS-5000-allGen-betaDist-varReg-varP-scaled.txt\" #path validation data, established \n",
    "PATH_STATS_EARLY = \"../models/early-betaDist-varReg-varP-domainChange/\" #path to model snapshots & RMSE file, established\n",
    "PATH_EMP_EARLY = \"../data/early/P-early-emp.txt\" #empirical data (generation \\t replicate \\t CN), established \n",
    "EARLY_TP = [0, 10, 20, 30, 40, 50, 60] #sequenced time points: early P-element invasion\n",
    "\n",
    "INPUT_PARAM = ['trans_prob', 'sel_alpha', 'sel_beta', 'l_pi', 'p_te'] #names var. input parameters\n",
    "\n",
    "PARAM_RANGES = ParameterSpace([ #define the parameter ranges \n",
    "    ContinuousParameter(\"trans_prob\", 0.15, 0.5),\n",
    "    ContinuousParameter(\"sel_alpha\", 0.001, 0.5),\n",
    "    ContinuousParameter(\"sel_beta\",10 , 20),\n",
    "    ContinuousParameter(\"l_pi\", 0.01, 0.10),\n",
    "    ContinuousParameter(\"p_te\", 0.15, 0.5)\n",
    "])\n",
    "\n",
    "N_SAMPLE_LHS = 1000000 #sample size from LHS for prediction & comparison to empirical data \n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000000, 5])\n"
     ]
    }
   ],
   "source": [
    "candidates = LatinDesign(PARAM_RANGES).get_samples(N_SAMPLE_LHS) #LHS sample\n",
    "candidates = torch.from_numpy(candidates).float().contiguous() #reformat\n",
    "candidates_numpy = candidates.numpy()\n",
    "\n",
    "print(candidates.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GP: early \n",
    "\n",
    "## Set up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 5])\n",
      "torch.float32\n",
      "torch.Size([1000, 6])\n",
      "torch.float32\n",
      "torch.Size([5000, 5])\n",
      "torch.float32\n",
      "torch.Size([5000, 6])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = prep_data(data_path=PATH_TRAIN_EARLY, input_params=INPUT_PARAM, time_points=EARLY_TP) #generate training data\n",
    "val_x, val_y = prep_data(data_path=PATH_VAL_EARLY, input_params=INPUT_PARAM, time_points=EARLY_TP) #generate validation data \n",
    "\n",
    "for i in train_x, train_y, val_x, val_y: #sanity checks \n",
    "    print(i.shape)\n",
    "    print(i.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=6) #set-up GP \n",
    "model = MultitaskGPModel(train_x, train_y, likelihood)\n",
    "model, likelihood, _ = trainGP(model=model, likelihood=likelihood,  learning_rate=0.01, iterationcount=1, train_x=train_x, train_y=train_y) #pre-requisite for loading hyper parameters\n",
    "\n",
    "if cuda_available():\n",
    "    model = model.cuda()\n",
    "    likelihood = likelihood.cuda()\n",
    "    train_x = train_x.cuda()\n",
    "    train_y = train_y.cuda()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/early-betaDist-varReg-varP-domainChange/P-GP-18.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = pd.read_csv(f\"{PATH_STATS_EARLY}/stats-GP.txt\", sep='\\t', header=0) #load model with lowest RMSE on validation data \n",
    "min_id= stats['validation_rmse'].idxmin()\n",
    "toload = f\"{PATH_STATS_EARLY}P-GP-{stats['round'][min_id]}.pth\"\n",
    "print(toload)\n",
    "model.load_state_dict(torch.load(toload))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4519)\n",
      "0.4522340297698974\n"
     ]
    }
   ],
   "source": [
    "lower_val, pred_val, upper_val = GPpredict_batch(df=val_x, model=model, likelihood=likelihood) #sanity check \n",
    "_, rmse_val = calculate_rmse(predictions=pred_val, observations=val_y)\n",
    "print(rmse_val)\n",
    "print(stats['validation_rmse'][min_id])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read empirical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gen  replicate     CN\n",
      "0     0          1   0.85\n",
      "1    10          1   3.89\n",
      "2    20          1  15.73\n",
      "3    30          1  15.94\n",
      "4    40          1  15.69\n",
      "5    50          1  15.74\n",
      "6    60          1  17.35\n",
      "7     0          3   0.80\n",
      "8    10          3   5.32\n",
      "9    20          3  13.68\n",
      "10   30          3  13.08\n",
      "11   40          3  13.09\n",
      "12   50          3  13.32\n",
      "13   60          3  14.04\n",
      "14    0          5   0.92\n",
      "15   10          5   4.38\n",
      "16   20          5  15.59\n",
      "17   30          5  16.20\n",
      "18   40          5  16.24\n",
      "19   50          5  15.04\n",
      "20   60          5  15.64\n"
     ]
    }
   ],
   "source": [
    "emp = pd.read_csv(PATH_EMP_EARLY, sep=\"\\t\", header=0)\n",
    "print(emp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, candidates_y_early, _ = GPpredict_batch(df = candidates, model=model, likelihood=likelihood) #prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 5)\n",
      "torch.Size([1000000, 6])\n"
     ]
    }
   ],
   "source": [
    "print(candidates_numpy.shape)\n",
    "print(candidates_y_early.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.5959364685651489, Mean: 3.1005742176073583, Max: 39.27607949372286\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nrmse_stat_early = np.array([calculate_sum_nrmse(emp, candidate, time_points=EARLY_TP[1:]) for candidate in candidates_y_early])\n",
    "print(f\"Min: {np.min(nrmse_stat_early)}, Mean: {np.mean(nrmse_stat_early)}, Max: {np.max(nrmse_stat_early)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.27704808,  0.48397985, 10.32680511,  0.01369418,  0.18897092,\n",
       "         0.59593647],\n",
       "       [ 0.27390122,  0.47886661, 10.62766457,  0.01536737,  0.23766187,\n",
       "         0.60544114],\n",
       "       [ 0.27544683,  0.49470687, 10.45795536,  0.01469939,  0.28756487,\n",
       "         0.60935597],\n",
       "       [ 0.27978298,  0.46004182, 10.64761543,  0.01646402,  0.23240453,\n",
       "         0.61238121],\n",
       "       [ 0.28147733,  0.48667195, 10.54162502,  0.01345208,  0.19820848,\n",
       "         0.61487642]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_x_candidates(x = candidates_numpy, score = nrmse_stat_early, top_x=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_x, train_y, val_x, val_y, likelihood, model, lower_val, upper_val, pred_val, rmse_val #clean-up \n",
    "torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GP: established \n",
    "\n",
    "## Set up Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 5])\n",
      "torch.float32\n",
      "torch.Size([1000, 6])\n",
      "torch.float32\n",
      "torch.Size([5000, 5])\n",
      "torch.float32\n",
      "torch.Size([5000, 6])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = prep_data(data_path=PATH_TRAIN_EST, input_params=INPUT_PARAM, time_points=ESTABLISHED_TP) #generate training data\n",
    "val_x, val_y = prep_data(data_path=PATH_VAL_EST, input_params=INPUT_PARAM, time_points=ESTABLISHED_TP) #generate validation data \n",
    "\n",
    "for i in train_x, train_y, val_x, val_y: #sanity checks \n",
    "    print(i.shape)\n",
    "    print(i.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=6) #set-up GP \n",
    "model = MultitaskGPModel(train_x, train_y, likelihood)\n",
    "model, likelihood, _ = trainGP(model=model, likelihood=likelihood,  learning_rate=0.01, iterationcount=1, train_x=train_x, train_y=train_y) #pre-requisite for loading hyper parameters\n",
    "\n",
    "if cuda_available():\n",
    "    model = model.cuda()\n",
    "    likelihood = likelihood.cuda()\n",
    "    train_x = train_x.cuda()\n",
    "    train_y = train_y.cuda()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/established-betaDist-varReg-varP-domainChange/P-GP-19.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = pd.read_csv(f\"{PATH_STATS_EST}/stats-GP.txt\", sep='\\t', header=0) #load model with lowest RMSE on validation data \n",
    "min_id= stats['validation_rmse'].idxmin()\n",
    "toload = f\"{PATH_STATS_EST}P-GP-{stats['round'][min_id]}.pth\"\n",
    "print(toload)\n",
    "model.load_state_dict(torch.load(toload))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6583)\n",
      "0.658774733543396\n"
     ]
    }
   ],
   "source": [
    "lower_val, pred_val, upper_val = GPpredict_batch(df=val_x, model=model, likelihood=likelihood) #sanity check \n",
    "_, rmse_val = calculate_rmse(predictions=pred_val, observations=val_y)\n",
    "print(rmse_val)\n",
    "print(stats['validation_rmse'][min_id])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read empirical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gen  replicate     CN\n",
      "0    30          3  14.05\n",
      "1    30          4  16.29\n",
      "2    30          5  14.76\n",
      "3    60          3  15.35\n",
      "4    60          4  19.31\n",
      "5    60          5  14.09\n",
      "6     0          3   6.89\n",
      "7     0          4   7.10\n",
      "8     0          5   6.78\n",
      "9    10          3   6.27\n",
      "10   10          4   7.03\n",
      "11   10          5   4.42\n",
      "12   15          3  15.25\n",
      "13   15          4  12.43\n",
      "14   15          5  11.97\n",
      "15   20          3  13.82\n",
      "16   20          4  13.13\n",
      "17   20          5  14.31\n",
      "18   25          3  13.71\n",
      "19   25          4  14.55\n",
      "20   25          5  15.54\n"
     ]
    }
   ],
   "source": [
    "emp = pd.read_csv(PATH_EMP_EST, sep=\"\\t\", header=0)\n",
    "print(emp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_, candidates_y_established, _ = GPpredict_batch(df = candidates, model=model, likelihood=likelihood) #prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 5)\n",
      "torch.Size([1000000, 6])\n"
     ]
    }
   ],
   "source": [
    "print(candidates_numpy.shape)\n",
    "print(candidates_y_established.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.6854921428622563, Mean: 3.561230164878388, Max: 41.336325922172826\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nrmse_stat_established = np.array([calculate_sum_nrmse(emp, candidate, time_points=ESTABLISHED_TP[1:]) for candidate in candidates_y_established])\n",
    "print(f\"Min: {np.min(nrmse_stat_established)}, Mean: {np.mean(nrmse_stat_established)}, Max: {np.max(nrmse_stat_established)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40375087,  0.45134974, 10.10243511,  0.01761737,  0.16050087,\n",
       "         0.68549214],\n",
       "       [ 0.40831941,  0.48807514, 10.6625948 ,  0.0160988 ,  0.15134943,\n",
       "         0.68715219],\n",
       "       [ 0.42350698,  0.45715711, 11.16285515,  0.01920705,  0.15243793,\n",
       "         0.69026574],\n",
       "       [ 0.36371821,  0.43606937, 11.92991543,  0.02373045,  0.15849608,\n",
       "         0.69083283],\n",
       "       [ 0.40364379,  0.4983246 , 11.27873516,  0.01612527,  0.15437238,\n",
       "         0.69204572]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_x_candidates(x = candidates_numpy, score = nrmse_stat_established, top_x=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_x, train_y, val_x, val_y, likelihood, model, lower_val, upper_val, pred_val, rmse_val #clean-up \n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrmse_stat_early = nrmse_stat_early.reshape(-1, 1) #reshape 1D array\n",
    "nrmse_stat_established = nrmse_stat_established.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "(1000000, 19)\n"
     ]
    }
   ],
   "source": [
    "column_names = INPUT_PARAM + [\"NRMSE_EARLY\", \"NRMSE_EST\"] + [f\"EARLY_TP{gen}\" for gen in EARLY_TP[1:]] + [f\"EST_TP{gen}\" for gen in ESTABLISHED_TP[1:]] #generate column names \n",
    "res = np.concatenate((candidates_numpy, nrmse_stat_early, nrmse_stat_established, candidates_y_early, candidates_y_established), axis = 1 ) #generate result df \n",
    "\n",
    "print(len(column_names))\n",
    "print(res.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"../pred/P-GP-joint-pred.txt\", res, delimiter='\\t', header='\\t'.join(column_names), comments='', fmt = '%.6f') #save result df "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPDummy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
