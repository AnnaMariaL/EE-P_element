{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages\n",
    "\n",
    "This section contains the packages necessary for this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch\n",
    "import gc\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader #batch loading \n",
    "from torch.cuda import is_available as cuda_available, empty_cache #GPU usage \n",
    "\n",
    "from emukit.core import ParameterSpace, ContinuousParameter\n",
    "from emukit.core.initial_designs.latin_design import LatinDesign\n",
    "\n",
    "import warnings \n",
    "#warnings.filterwarnings(\"ignore\") #please be really sure about this one \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip freeze > requirements-02.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SET_NUM_POINTS = 2500"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes\n",
    "\n",
    "This section contains the - very short - class implementation for the GP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultitaskGPModel(gpytorch.models.ExactGP): #Multi Class GP with 6 (correlated) outputs\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.MultitaskMean(\n",
    "            gpytorch.means.ConstantMean(), num_tasks=6\n",
    "        )\n",
    "        self.covar_module = gpytorch.kernels.MultitaskKernel(\n",
    "            gpytorch.kernels.RBFKernel(ard_num_dims=7), num_tasks=6, rank=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "\n",
    "This section contains function used in the GP training.\n",
    "\n",
    "## Functions for: Data reformatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter_data_by_GEN: read full simulation data & filter for sequenced time points\n",
    "def filter_data_by_GEN(data_path, values): \n",
    "    df = pd.read_csv(data_path, sep='\\t', header=0) #read data \n",
    "    df['GEN'] = df['GEN'] - 1 #change from 1-based to 0-based\n",
    "    filtered_df = df[df['GEN'].isin(values)] #filter for empirical available time points \n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "#select_columns_by_names: subset training data based on column names \n",
    "def select_columns_by_names(df, column_names):\n",
    "    selected_columns = df[df['GEN']== 0] #for parameter extraction: removes duplicated entries\n",
    "    selected_columns = selected_columns[column_names]\n",
    "    selected_columns = selected_columns.to_numpy(dtype = \"float\")\n",
    "    return torch.from_numpy(selected_columns).float().contiguous()\n",
    "\n",
    "\n",
    "#get_CN_for_GEN get CN ( = response) for specific generation GEN\n",
    "def get_CN_for_GEN(df, GEN):\n",
    "    filtered_df = df[df['GEN'] == GEN] #filter for specific GEN\n",
    "    \n",
    "    if filtered_df.empty:\n",
    "        return None \n",
    "    else:\n",
    "        CN = filtered_df['m'].to_numpy(dtype = \"float\")\n",
    "        return torch.from_numpy(CN).float().contiguous().flatten()\n",
    "\n",
    "#prep_data: re-formatting of SLiMULATION output for GP \n",
    "def prep_data(data_path, input_params, time_points):\n",
    "    df = filter_data_by_GEN(data_path=data_path, values=time_points) #filter data\n",
    "    df_x = select_columns_by_names(df = df, column_names=input_params) #extract input parameters \n",
    "    y_list = [] \n",
    "\n",
    "    for gen in time_points[1:]: #exclude gen = 0 (no predictions); extract y-values (= CN | GEN)\n",
    "        CN_values = get_CN_for_GEN(df, gen)\n",
    "        y_list.append(CN_values)\n",
    "    y = torch.stack(y_list, dim=-1) #reformat y-values \n",
    "\n",
    "    return df_x, y #return reformatted input & output data \n",
    "\n",
    "#calculate_rmse: calculate RMSE \n",
    "def calculate_rmse(predictions, observations):\n",
    "    squared_error = (predictions - observations)**2\n",
    "    mse = squared_error.mean(dim=0) #MSE across first dimension (= input parameters)\n",
    "    rmse_per_timepoint = torch.sqrt(mse)\n",
    "    overall_rmse = torch.sqrt(squared_error.mean()) #overall RMSE\n",
    "    return rmse_per_timepoint, overall_rmse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for: GP handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPpredict_batch: prediction with GP with batch loading onto GPU\n",
    "def GPpredict_batch(df, model, likelihood):\n",
    "    if cuda_available(): # Shift data to GPU if available \n",
    "        df = df.cuda()\n",
    "    \n",
    "    loader = DataLoader(TensorDataset(df), batch_size=1024, shuffle=False) # Batch loading onto GPU \n",
    "    lower, mean, upper = [], [], []\n",
    "\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        for batch in loader:\n",
    "            batch_predictions = likelihood(model(batch[0]))\n",
    "            batch_means = batch_predictions.mean\n",
    "            batch_lowers, batch_uppers = batch_predictions.confidence_region()\n",
    "            \n",
    "            if cuda_available():\n",
    "                lower.append(batch_lowers.cpu())\n",
    "                mean.append(batch_means.cpu())\n",
    "                upper.append(batch_uppers.cpu())\n",
    "            else:\n",
    "                lower.append(batch_lowers)\n",
    "                mean.append(batch_means)\n",
    "                upper.append(batch_uppers)\n",
    "\n",
    "    lower = torch.cat(lower, dim=0)\n",
    "    mean = torch.cat(mean, dim=0)\n",
    "    upper = torch.cat(upper, dim=0)\n",
    "    \n",
    "    return lower, mean, upper\n",
    "\n",
    "#trainGP: train Gaussian process for <iterationcount> iterations, using learning rate <learning_rate> \n",
    "def trainGP(model, likelihood, train_x, train_y, learning_rate, iterationcount):\n",
    "    model.train() #set to training modus\n",
    "    likelihood.train()\n",
    "\n",
    "    # Use the adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr= learning_rate)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    for i in range(iterationcount): #train for <iterationcount> interations \n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_x)\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "        #if (i + 1) % 500==0 or i == 0: #output for tracking of loss on training data \n",
    "            #print('Iter %d/%d - Loss: %.3f' % (i + 1, iterationcount, loss.item()))\n",
    "        if i == (iterationcount-1):\n",
    "            lossCount = loss.item() #save Loss at end of training\n",
    "        optimizer.step()\n",
    "        if cuda_available():\n",
    "            empty_cache()\n",
    "\n",
    "    model.eval() #set back to evaluation mode \n",
    "    likelihood.eval()\n",
    "    return model, likelihood, lossCount #return trained model & loss at the end of trianing\n",
    "\n",
    "#singlePrediction: generate prediction for a single input parameter combination\n",
    "    #trans_prob: transposition probability\n",
    "    #sel_alpha: alpha parameter, DFE beta distribution\n",
    "    #sel_beta: beta parameter, DFE beta distribution\n",
    "    #l_pi: proportion of chromosome with regulatory function\n",
    "    #p_te: proportion of isofemale lines that have P-element\n",
    "    #p_exc: excision probability\n",
    "    #h: dominance coefficient\n",
    "    #model: GP model\n",
    "    #likelihood: GP likelihood \n",
    "def singlePrediction(trans_prob, sel_alpha, sel_beta, l_pi, p_te, p_exc, h, model, likelihood):\n",
    "    param_array = np.array([trans_prob, sel_alpha, sel_beta, l_pi, p_te, p_exc, h]) #generate input param array\n",
    "    param_array = torch.from_numpy(param_array).float().contiguous() #reformat \n",
    "    param_array = param_array.view(1, -1)\n",
    "    _, pred_mean, _ = GPpredict_batch(df=param_array, model=model, likelihood=likelihood) #obtain GP prediction\n",
    "    return pred_mean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for: Empirical Data Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate_sum_nrsme: calculate NRMSE sum between empirical data and GP prediction\n",
    "def calculate_sum_nrmse(obs_df, pred_torch, time_points):\n",
    "    pred = pred_torch.numpy()\n",
    "    diff_stat = []\n",
    "\n",
    "    for gen in range(len(time_points)):\n",
    "        CN_gen = obs_df[obs_df['gen'] == time_points[gen]]['CN'].to_numpy()\n",
    "        nrmse_gen = np.sqrt(np.sum((CN_gen - pred[gen])**2)/len(CN_gen))/np.mean(CN_gen)\n",
    "        diff_stat.append(nrmse_gen)\n",
    "    return np.sum(diff_stat)\n",
    "\n",
    "\n",
    "#top_x_candidates: return top_x rows of numpy array x with lowest score \n",
    "def top_x_candidates(x, score, top_x):\n",
    "    y = np.column_stack((x, score))\n",
    "    y_sorted = y[y[:, -1].argsort()]\n",
    "    return y_sorted[:top_x]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables\n",
    "This section contains global variables. If you use the provided file structure, <i>N_SAMPLE_LHS</i> is the only variable that -maybe - needs to be changed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLE_LHS = 10000000 #sample size from LHS for prediction & comparison to empirical data \n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN_EST = f\"../data/established/train-LHS-{TRAIN_SET_NUM_POINTS}-allGen-betaDist-varReg-varP-ExcEvents-rescaled.txt\" #path training data, established\n",
    "PATH_VAL_EST = \"../data/established/val-LHS-10000-allGen-betaDist-varReg-varP-ExcEvents-rescaled.txt\" #path validation data, established \n",
    "PATH_STATS_EST = \"../models/established/\" #path to model snapshots & RMSE file, established\n",
    "PATH_EMP_EST = \"../data/established/P-established-emp.txt\" #empirical data (generation \\t replicate \\t CN), established\n",
    "ESTABLISHED_TP = [0, 10, 15, 20, 25, 30, 60] #sequenced time points: established P-element invasion (do not change)\n",
    "\n",
    "PATH_TRAIN_EARLY = f\"../data/early/train-LHS-{TRAIN_SET_NUM_POINTS}-allGen-betaDist-varReg-varP-ExcEvents-rescaled.txt\" #path training data, early\n",
    "PATH_VAL_EARLY = \"../data/early/val-LHS-10000-allGen-betaDist-varReg-varP-ExcEvents-rescaled.txt\" #path validation data, early \n",
    "PATH_STATS_EARLY = \"../models/early/\" #path to model snapshots & RMSE file, early\n",
    "PATH_EMP_EARLY = \"../data/early/P-early-emp.txt\" #empirical data (generation \\t replicate \\t CN), early\n",
    "EARLY_TP = [0, 10, 20, 30, 40, 50, 60] #sequenced time points: early P-element invasion (do not change)\n",
    "\n",
    "INPUT_PARAM = ['trans_prob', 'sel_alpha', 'sel_beta', 'l_pi', 'p_te', 'p_exc', 'h'] #names var. input parameters\n",
    "\n",
    "PARAM_RANGES = ParameterSpace([ #define the parameter ranges \n",
    "    ContinuousParameter(\"trans_prob\", 0.15, 0.5),\n",
    "    ContinuousParameter(\"sel_alpha\", 0.001, 0.5),\n",
    "    ContinuousParameter(\"sel_beta\",10 , 20),\n",
    "    ContinuousParameter(\"l_pi\", 0.01, 0.10),\n",
    "    ContinuousParameter(\"p_te\", 0.15, 0.5),\n",
    "    ContinuousParameter(\"p_exc\", 0.0, 0.25),\n",
    "    ContinuousParameter(\"h\", 0.0, 1.0)\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000000, 7])\n"
     ]
    }
   ],
   "source": [
    "candidates = LatinDesign(PARAM_RANGES).get_samples(N_SAMPLE_LHS) #LHS sample\n",
    "candidates = torch.from_numpy(candidates).float().contiguous() #reformat\n",
    "candidates_numpy = candidates.numpy()\n",
    "\n",
    "print(candidates.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GP: early \n",
    "\n",
    "## Set up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2500, 7])\n",
      "torch.float32\n",
      "torch.Size([2500, 6])\n",
      "torch.float32\n",
      "torch.Size([10000, 7])\n",
      "torch.float32\n",
      "torch.Size([10000, 6])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = prep_data(data_path=PATH_TRAIN_EARLY, input_params=INPUT_PARAM, time_points=EARLY_TP) #prep training data\n",
    "val_x, val_y = prep_data(data_path=PATH_VAL_EARLY, input_params=INPUT_PARAM, time_points=EARLY_TP) #prep validation data \n",
    "\n",
    "for i in train_x, train_y, val_x, val_y: #sanity checks: format... X = 10,000 rows x 7 model parameters; Y = 10,000 rows x 6 P-element copy numbers (time series)\n",
    "    print(i.shape)\n",
    "    print(i.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=6) #set-up GP \n",
    "model = MultitaskGPModel(train_x, train_y, likelihood)\n",
    "model, likelihood, _ = trainGP(model=model, likelihood=likelihood,  learning_rate=1e-10, iterationcount=1, train_x=train_x, train_y=train_y) #pre-requisite for loading hyper parameters\n",
    "\n",
    "if cuda_available():\n",
    "    model = model.cuda()\n",
    "    likelihood = likelihood.cuda()\n",
    "    train_x = train_x.cuda()\n",
    "    train_y = train_y.cuda()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/early/P-GP-36.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = pd.read_csv(f\"{PATH_STATS_EARLY}/stats-GP.txt\", sep='\\t', header=0) #load model with lowest RMSE on validation data \n",
    "min_id= stats['validation_rmse'].idxmin()\n",
    "toload = f\"{PATH_STATS_EARLY}P-GP-{stats['round'][min_id]}.pth\"\n",
    "print(toload)\n",
    "model.load_state_dict(torch.load(toload))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6329)\n",
      "0.6354441046714783\n"
     ]
    }
   ],
   "source": [
    "lower_val, pred_val, upper_val = GPpredict_batch(df=val_x, model=model, likelihood=likelihood) #sanity check \n",
    "_, rmse_val = calculate_rmse(predictions=pred_val, observations=val_y)\n",
    "print(rmse_val)\n",
    "print(stats['validation_rmse'][min_id])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read empirical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gen  replicate     CN\n",
      "0     0          1   0.85\n",
      "1    10          1   3.89\n",
      "2    20          1  15.73\n",
      "3    30          1  15.94\n",
      "4    40          1  15.69\n",
      "5    50          1  15.74\n",
      "6    60          1  17.35\n",
      "7     0          3   0.80\n",
      "8    10          3   5.32\n",
      "9    20          3  13.68\n",
      "10   30          3  13.08\n",
      "11   40          3  13.09\n",
      "12   50          3  13.32\n",
      "13   60          3  14.04\n",
      "14    0          5   0.92\n",
      "15   10          5   4.38\n",
      "16   20          5  15.59\n",
      "17   30          5  16.20\n",
      "18   40          5  16.24\n",
      "19   50          5  15.04\n",
      "20   60          5  15.64\n"
     ]
    }
   ],
   "source": [
    "emp = pd.read_csv(PATH_EMP_EARLY, sep=\"\\t\", header=0)\n",
    "print(emp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, candidates_y_early, _ = GPpredict_batch(df = candidates, model=model, likelihood=likelihood) #prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000000, 7)\n",
      "torch.Size([10000000, 6])\n"
     ]
    }
   ],
   "source": [
    "print(candidates_numpy.shape)\n",
    "print(candidates_y_early.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.5795683598425069, Mean: 3.148029339298446, Max: 45.69618886243089\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nrmse_stat_early = np.array([calculate_sum_nrmse(emp, candidate, time_points=EARLY_TP[1:]) for candidate in candidates_y_early]) #calculate normalized RMSE\n",
    "print(f\"Min: {np.min(nrmse_stat_early)}, Mean: {np.mean(nrmse_stat_early)}, Max: {np.max(nrmse_stat_early)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.07185084e-01, 3.17427754e-01, 1.01350193e+01, 1.05918441e-02,\n",
       "        1.72232375e-01, 2.47341376e-02, 9.59198833e-01, 5.79568360e-01],\n",
       "       [2.99885690e-01, 3.06051850e-01, 1.09573393e+01, 1.51561406e-02,\n",
       "        1.62580729e-01, 2.25681122e-02, 9.01678979e-01, 5.82535556e-01],\n",
       "       [3.14732999e-01, 3.46686065e-01, 1.21256819e+01, 1.22904778e-02,\n",
       "        1.89505041e-01, 6.32840097e-02, 8.93953741e-01, 5.85116667e-01],\n",
       "       [3.02598447e-01, 3.20405930e-01, 1.05912523e+01, 1.18314503e-02,\n",
       "        1.61763623e-01, 3.24978381e-02, 8.54486763e-01, 5.85817575e-01],\n",
       "       [3.46152306e-01, 3.03287536e-01, 1.00380917e+01, 1.07771279e-02,\n",
       "        1.75187767e-01, 1.81335583e-01, 8.88555944e-01, 5.89228395e-01]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_x_candidates(x = candidates_numpy, score = nrmse_stat_early, top_x=5) #top 5 candidates with lowest normalized RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_x, train_y, val_x, val_y, likelihood, model, lower_val, upper_val, pred_val, rmse_val #clean-up \n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GP: established \n",
    "\n",
    "## Set up Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2500, 7])\n",
      "torch.float32\n",
      "torch.Size([2500, 6])\n",
      "torch.float32\n",
      "torch.Size([10000, 7])\n",
      "torch.float32\n",
      "torch.Size([10000, 6])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = prep_data(data_path=PATH_TRAIN_EST, input_params=INPUT_PARAM, time_points=ESTABLISHED_TP) #prep training data\n",
    "val_x, val_y = prep_data(data_path=PATH_VAL_EST, input_params=INPUT_PARAM, time_points=ESTABLISHED_TP) #prep validation data \n",
    "\n",
    "for i in train_x, train_y, val_x, val_y: #sanity checks \n",
    "    print(i.shape)\n",
    "    print(i.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=6) #set-up GP \n",
    "model = MultitaskGPModel(train_x, train_y, likelihood)\n",
    "model, likelihood, _ = trainGP(model=model, likelihood=likelihood,  learning_rate=1e-10, iterationcount=1, train_x=train_x, train_y=train_y) #pre-requisite for loading hyper parameters\n",
    "\n",
    "if cuda_available():\n",
    "    model = model.cuda()\n",
    "    likelihood = likelihood.cuda()\n",
    "    train_x = train_x.cuda()\n",
    "    train_y = train_y.cuda()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/established/P-GP-44.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = pd.read_csv(f\"{PATH_STATS_EST}/stats-GP.txt\", sep='\\t', header=0) #load model with lowest RMSE on validation data \n",
    "min_id= stats['validation_rmse'].idxmin()\n",
    "toload = f\"{PATH_STATS_EST}P-GP-{stats['round'][min_id]}.pth\"\n",
    "print(toload)\n",
    "model.load_state_dict(torch.load(toload))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7922)\n",
      "0.7959458231925964\n"
     ]
    }
   ],
   "source": [
    "lower_val, pred_val, upper_val = GPpredict_batch(df=val_x, model=model, likelihood=likelihood) #sanity check \n",
    "_, rmse_val = calculate_rmse(predictions=pred_val, observations=val_y)\n",
    "print(rmse_val)\n",
    "print(stats['validation_rmse'][min_id])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read empirical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gen  replicate     CN\n",
      "0    30          3  14.05\n",
      "1    30          4  16.29\n",
      "2    30          5  14.76\n",
      "3    60          3  15.35\n",
      "4    60          4  19.31\n",
      "5    60          5  14.09\n",
      "6     0          3   6.89\n",
      "7     0          4   7.10\n",
      "8     0          5   6.78\n",
      "9    10          3   6.27\n",
      "10   10          4   7.03\n",
      "11   10          5   4.42\n",
      "12   15          3  15.25\n",
      "13   15          4  12.43\n",
      "14   15          5  11.97\n",
      "15   20          3  13.82\n",
      "16   20          4  13.13\n",
      "17   20          5  14.31\n",
      "18   25          3  13.71\n",
      "19   25          4  14.55\n",
      "20   25          5  15.54\n"
     ]
    }
   ],
   "source": [
    "emp = pd.read_csv(PATH_EMP_EST, sep=\"\\t\", header=0)\n",
    "print(emp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_, candidates_y_established, _ = GPpredict_batch(df = candidates, model=model, likelihood=likelihood) #prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000000, 7)\n",
      "torch.Size([10000000, 6])\n"
     ]
    }
   ],
   "source": [
    "print(candidates_numpy.shape)\n",
    "print(candidates_y_established.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.681475035779951, Mean: 3.5993749211846224, Max: 50.07265033969917\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nrmse_stat_established = np.array([calculate_sum_nrmse(emp, candidate, time_points=ESTABLISHED_TP[1:]) for candidate in candidates_y_established]) #calculate normalized RMSE\n",
    "print(f\"Min: {np.min(nrmse_stat_established)}, Mean: {np.mean(nrmse_stat_established)}, Max: {np.max(nrmse_stat_established)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.15778607e-01, 2.99001515e-01, 1.04220409e+01, 1.31922867e-02,\n",
       "        1.82416558e-01, 5.98676130e-02, 8.39276254e-01, 6.81475036e-01],\n",
       "       [4.43185300e-01, 4.09634382e-01, 1.88445549e+01, 2.20917389e-02,\n",
       "        1.55756220e-01, 1.91914868e-02, 9.38082457e-01, 6.84158833e-01],\n",
       "       [4.16700959e-01, 4.52462435e-01, 1.97778625e+01, 1.94471162e-02,\n",
       "        1.64200842e-01, 6.31883144e-02, 8.48489225e-01, 6.85212520e-01],\n",
       "       [4.46784139e-01, 4.06741530e-01, 1.98561611e+01, 2.26343758e-02,\n",
       "        1.57646433e-01, 4.98566143e-02, 9.77547765e-01, 6.85318712e-01],\n",
       "       [4.30313587e-01, 3.38911206e-01, 1.14197178e+01, 1.56328697e-02,\n",
       "        1.77469283e-01, 1.23311736e-01, 7.08727777e-01, 6.87391385e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_x_candidates(x = candidates_numpy, score = nrmse_stat_established, top_x=5) #top 5 canidates with lowest normalized RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_x, train_y, val_x, val_y, likelihood, model, lower_val, upper_val, pred_val, rmse_val #clean-up \n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storage \n",
    "After running the notebook, there should be a <i>P-GP-joint-pred.txt</i> file in the <i>pred</i> directory with <i>N_SAMPLE_LHS</i> rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrmse_stat_early = nrmse_stat_early.reshape(-1, 1) #reshape 1D array\n",
    "nrmse_stat_established = nrmse_stat_established.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "(10000000, 21)\n"
     ]
    }
   ],
   "source": [
    "column_names = INPUT_PARAM + [\"NRMSE_EARLY\", \"NRMSE_EST\"] + [f\"EARLY_TP{gen}\" for gen in EARLY_TP[1:]] + [f\"EST_TP{gen}\" for gen in ESTABLISHED_TP[1:]] #generate column names \n",
    "res = np.concatenate((candidates_numpy, nrmse_stat_early, nrmse_stat_established, candidates_y_early, candidates_y_established), axis = 1 ) #generate result df \n",
    "\n",
    "print(len(column_names))\n",
    "print(res.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points_for_savename = f\"_{int(N_SAMPLE_LHS/1000000)}m\"\n",
    "np.savetxt(f\"../pred/P-GP-joint-pred{num_points_for_savename}.txt\", res, delimiter='\\t', header='\\t'.join(column_names), comments='', fmt = '%.6f') #save result df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
